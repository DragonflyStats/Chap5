\documentclass[Main.tex]{subfiles}
\begin{document}
	

	\subsection{Quantifying Influence}  %1.1.6
	
	The basic procedure for quantifying influence is simple as follows:
	
	\begin{itemize}
		\item Fit the model to the data and obtain estimates of all parameters.
		\item Remove one or more data points from the analysis and compute updated estimates of model parameters.
		\item Based on full- and reduced-data estimates, contrast quantities of interest to determine how the absence of the observations changes the analysis.
	\end{itemize}
	
	Cook (1986) introduces powerful tools for local-influence assessment and examining perturbations in the assumptions of a model. In particular the effect of local perturbations of parameters or observations are examined.
	
	%--------------------------------------------------------------%
	\newpage
	\section{Measures 2} %2.4
	
	\subsection{Cook's Distance} %2.4.1
	\begin{itemize}
		\item For variance components $\gamma$
	\end{itemize}
	
	Diagnostic tool for variance components
	\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]
	
	
	\subsection{Variance Ratio} %2.4.2
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	\subsection{Variance Ratio} %2.4.2
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	\subsection{Cook-Weisberg statistic} %2.4.3
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	

	\subsection{Andrews-Pregibon statistic} %2.4.4
		\begin{itemize}
			\item For fixed effect parameters $\beta$.
		\end{itemize}
		The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
		The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.

		
	%--------------------------------------------------------------%
	\newpage
	\section{Measures 2} %2.4
	
	
	\subsection{Cook's Distance} %2.4.1
	\begin{itemize}
		\item For variance components $\gamma$
	\end{itemize}
	
	
	Diagnostic tool for variance components
	\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]
	
	
	
	

	
	
	%---------------------------------------------------------------------------%
	%-------------------------------------------------------------------------------------------------------------------------------------%
	\section{Zewotir Measures of Influence in LME Models}%2.2
	%Zewotir page 161
	Zewotir describes a number of approaches to model diagnostics, investigating each of the following;
	\begin{itemize}
		\item Variance components
		\item Fixed effects parameters
		\item Prediction of the response variable and of random effects
		\item likelihood function
	\end{itemize}
	
	
	\newpage
	\subsubsection{Random Effects}
	
	A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.
	
	\subsubsection{linear functions}
	
	$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.
	
	
	\subsection{Information Ratio}
	
	
	%--------------------------------------------------------------%
	\newpage
	\section{Computation and Notation } %2.3
	with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
	compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.
	
	
	Zewotir remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
\section{Measures of Influence} %1.16

The impact of an observation on a regression fitting can be determined by the difference between the estimated regression coefficient of a model with all observations and the estimated coefficient when the particular observation is deleted. The measure DFBETA is the studentized value of this difference.

Influence arises at two stages of the LME model. Firstly when $V$ is estimated by $\hat{V}$, and subsequent
estimations of the fixed and random regression coefficients $\beta$ and $u$, given $\hat{V}$.


\subsection{DFFITS} %1.16.1
DFFITS is a statistical measured designed to a show how influential an observation is in a statistical model. It is closely related to the studentized residual.
\begin{displaymath} DFFITS = {\widehat{y_i} -
\widehat{y_{i(k)}} \over s_{(k)} \sqrt{h_{ii}}} \end{displaymath}


%-------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Influence Statistics for LME models} %1.1.4
Influence statistics can be coarsely grouped by the aspect of estimation that is their primary target:
\begin{itemize}
	\item overall measures compare changes in objective functions: (restricted) likelihood distance (Cook and Weisberg 1982, Ch. 5.2)
	\item influence on parameter estimates: Cook's  (Cook 1977, 1979), MDFFITS (Belsley, Kuh, and Welsch 1980, p. 32)
	\item influence on precision of estimates: CovRatio and CovTrace
	\item influence on fitted and predicted values: PRESS residual, PRESS statistic (Allen 1974), DFFITS (Belsley, Kuh, and Welsch 1980, p. 15)
	\item outlier properties: internally and externally studentized residuals, leverage
\end{itemize}
%---------------------------------------------------------------------------%



\section{Measures of Influence} %1.16

The impact of an observation on a regression fitting can be determined by the difference between the estimated regression coefficient of a model with all observations and the estimated coefficient when the particular observation is deleted. The measure DFBETA is the studentized value of this difference.

Influence arises at two stages of the LME model. Firstly when $V$ is estimated by $\hat{V}$, and subsequent
estimations of the fixed and random regression coefficients $\beta$ and $u$, given $\hat{V}$.


\subsection{DFBETA} %1.16.3
\begin{eqnarray}
	DFBETA_{a} &=& \hat{\beta} - \hat{\beta}_{(a)} \\
	&=& B(Y-Y_{\bar{a}}
\end{eqnarray}
%-------------------------------------------------------------------------------------------------------------------------------------%

\subsection{DFFITS} %1.16.1
DFFITS is a statistical measured designed to a show how influential an observation is in a statistical model. It is closely related to the studentized residual.
\begin{displaymath} DFFITS = {\widehat{y_i} -
		\widehat{y_{i(k)}} \over s_{(k)} \sqrt{h_{ii}}} \end{displaymath}


%================================================ %

\subsection{PRESS} %1.16.2
The prediction residual sum of squares (PRESS) is an value associated with this calculation. When fitting linear models, PRESS can be used as a criterion for model selection, with smaller values indicating better model fits.
\begin{equation}
	PRESS = \sum(y-y^{(k)})^2
\end{equation}


\begin{itemize}
	\item $e_{-Q} = y_{Q} - x_{Q}\hat{\beta}^{-Q}$
	\item $PRESS_{(U)} = y_{i} - x\hat{\beta}_{(U)}$
\end{itemize}

\subsection{DFBETA} %1.16.3
\begin{eqnarray}
	DFBETA_{a} &=& \hat{\beta} - \hat{\beta}_{(a)} \\
	&=& B(Y-Y_{\bar{a}}
\end{eqnarray}

%-------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Influential Observations : DFBeta and DFBetas}
% http://stats.stackexchange.com/questions/22161/how-to-read-cooks-distance-plots
Cook's distance refers to how far, on average, predicted y-values will move if the observation in question is dropped from the data set. dfbeta refers to how much a parameter estimate changes if the observation in question is dropped from the data set. Note that with k covariates, there will be k+1 dfbetas (the intercept,$\beta_0$, and 1 $\beta$ for each covariate). Cook's distance is presumably more important to you if you are doing predictive modeling, whereas dfbeta is more important in explanatory modeling.


\newpage


\newpage
%-------------------------------------------------------------------------------------------------------------------------------------%
\end{document}