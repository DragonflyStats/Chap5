\documentclass[Chap5amain.tex]{subfiles}
\begin{document}
	\section{Introduction}%1.1
	In classical linear models model diagnostics have been become a required part of any statistical analysis, and the methods are commonly available in statistical packages and standard textbooks on applied regression. However it has been noted by several papers that model diagnostics do not often accompany LME model analyses.
	Model diagnostic techniques determine whether or not the distributional assumptions are satisfied, and to assess the influence of unusual observations.
	
	\subsection{Model Data Agreement} %1.1.1
	\citet{schabenberger} describes the examination of model-data agreement as comprising several elements; residual analysis, goodness of fit, collinearity diagnostics and influence analysis.
	
	\subsection{Influence Diagnostics: Basic Idea and Statistics} %1.1.2
	%http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect024.htm
	
	The general idea of quantifying the influence of one or more observations relies on computing parameter estimates based on all data points, removing the cases in question from the data, refitting the model, and computing statistics based on the change between full-data and reduced-data estimation. 
	
	
	
	\subsection{Influence Analysis for LME Models} %1.1.3
	The linear mixed effects model is a useful methodology for fitting a wide range of models. However, linear mixed effects models are known to be sensitive to outliers. \citet{CPJ} advises that identification of outliers is necessary before conclusions may be drawn from the fitted model.
	
	Standard statistical packages concentrate on calculating and testing parameter estimates without considering the diagnostics of the model.The assessment of the effects of perturbations in data, on the outcome of the analysis, is known as statistical influence analysis. Influence analysis examines the robustness of the model. Influence analysis methodologies have been used extensively in classical linear models, and provided the basis for methodologies for use with LME models.
	Computationally inexpensive diagnostics tools have been developed to examine the issue of influence \citep{Zewotir}.
	Studentized residuals, error contrast matrices and the inverse of the response variance covariance matrix are regular components of these tools.
	
	\subsection{Influence Statistics for LME models} %1.1.4
	Influence statistics can be coarsely grouped by the aspect of estimation that is their primary target:
	\begin{itemize}
		\item overall measures compare changes in objective functions: (restricted) likelihood distance (Cook and Weisberg 1982, Ch. 5.2)
		\item influence on parameter estimates: Cook's  (Cook 1977, 1979), MDFFITS (Belsley, Kuh, and Welsch 1980, p. 32)
		\item influence on precision of estimates: CovRatio and CovTrace
		\item influence on fitted and predicted values: PRESS residual, PRESS statistic (Allen 1974), DFFITS (Belsley, Kuh, and Welsch 1980, p. 15)
		\item outlier properties: internally and externally studentized residuals, leverage
	\end{itemize}
	%---------------------------------------------------------------------------%
	
	
	\subsection{What is Influence} %1.1.5
	
	Broadly defined, influence is understood as the ability of a single or multiple data points, through their presence or absence in the data, to alter important aspects of the analysis, yield qualitatively different inferences, or violate assumptions of the statistical model. The goal of influence analysis is not primarily to mark data
	points for deletion so that a better model fit can be achieved for the reduced data, although this might be a result of influence analysis \citep{schabenberger}.
	
	%-------%
	\subsection{Quantifying Influence}  %1.1.6
	
	The basic procedure for quantifying influence is simple as follows:
	
	\begin{itemize}
		\item Fit the model to the data and obtain estimates of all parameters.
		\item Remove one or more data points from the analysis and compute updated estimates of model parameters.
		\item Based on full- and reduced-data estimates, contrast quantities of interest to determine how the absence of the observations changes the analysis.
	\end{itemize}
	
	\citet{cook86} introduces powerful tools for local-influence assessment and examining perturbations in the assumptions of a model. In particular the effect of local perturbations of parameters or observations are examined.
	
	
	%---------------------------------------------------------------------------%
	\newpage
	\section{Extension of techniques to LME Models} %1.2
	
	Model diagnostic techniques, well established for classical models, have since been adapted for use with linear mixed effects models.Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.
	
	Beckman, Nachtsheim and Cook (1987) \citet{Beckman} applied the \index{local influence}local influence method of Cook (1986) to the analysis of the linear mixed model.
	
	While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.
	
	If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect the following
	
	\begin{itemize}
		\item the estimates of fixed effects,
		\item the estimates of the precision of the fixed effects,
		\item the estimates of the covariance parameters,
		\item the estimates of the precision of the covariance parameters,
		\item fitted and predicted values.
	\end{itemize}
	
	
	
	
\subsection{What is Influence} %1.1.5

Broadly defined, influence is understood as the ability of a single or multiple data points, through their presence or absence in the data, to alter important aspects of the analysis, yield qualitatively different inferences, or violate assumptions of the statistical model. The goal of influence analysis is not primarily to mark data
points for deletion so that a better model fit can be achieved for the reduced data, although this might be a result of influence analysis \citep{schabenberger}.

%-------%
\subsection{Quantifying Influence}  %1.1.6

The basic procedure for quantifying influence is simple as follows:

\begin{itemize}
	\item Fit the model to the data and obtain estimates of all parameters.
	\item Remove one or more data points from the analysis and compute updated estimates of model parameters.
	\item Based on full- and reduced-data estimates, contrast quantities of interest to determine how the absence of the observations changes the analysis.
\end{itemize}

\citet{cook86} introduces powerful tools for local-influence assessment and examining perturbations in the assumptions of a model. In particular the effect of local perturbations of parameters or observations are examined.



%---------------------------------------------------------------------------%
\newpage
\section{Residual diagnostics} %1.3
For classical linear models, residual diagnostics are typically implemented as a plot of the observed residuals and the predicted values. A visual inspection for the presence of trends inform the analyst on the validity of distributional assumptions, and to detect outliers and influential observations.

\section{Introduction}%1.1
In classical linear models model diagnostics have been become a required part of any statistical analysis, and the methods are commonly available in statistical packages and standard textbooks on applied regression. However it has been noted by several papers that model diagnostics do not often accompany LME model analyses.
Model diagnostic techniques determine whether or not the distributional assumptions are satisfied, and to assess the influence of unusual observations.

\subsection{Model Data Agreement} %1.1.1
\citet{schabenberger} describes the examination of model-data agreement as comprising several elements; residual analysis, goodness of fit, collinearity diagnostics and influence analysis.



\subsection*{What is Influence} %1.1.5

Broadly defined, influence is understood as the ability of a single or multiple data points, through their presence or absence in the data, to alter important aspects of the analysis, yield qualitatively different inferences, or violate assumptions of the statistical model. The goal of influence analysis is not primarily to mark data
points for deletion so that a better model fit can be achieved for the reduced data, although this might be a result of influence analysis \textit{schabenberger}.

%-------%
\subsection*{Quantifying Influence}  %1.1.6

The basic procedure for quantifying influence is simple as follows:

\begin{itemize}
\item Fit the model to the data and obtain estimates of all parameters.
\item Remove one or more data points from the analysis and compute updated estimates of model parameters.
\item Based on full- and reduced-data estimates, contrast quantities of interest to determine how the absence of the observations changes the analysis.
\end{itemize}

Cook (1986) introduces powerful tools for local-influence assessment and examining perturbations in the assumptions of a model. In particular the effect of local perturbations of parameters or observations are examined.

%---------------------------------------------------------------------------%
\newpage
\section{Influence analysis} %1.7


Likelihood based estimation methods, such as ML and REML, are sensitive to unusual observations. Influence diagnostics are formal techniques that assess the influence of observations on parameter estimates for $\beta$ and $\theta$. A common technique is to refit the model with an observation or group of observations omitted.


\citet{west} examines a group of methods that examine various aspects of influence diagnostics for LME models.
For overall influence, the most common approaches are the `likelihood distance' and the `restricted likelihood distance'.


\subsection{Cook's 1986 paper on Local Influence}%1.7.1
Cook 1986 introduced methods for local influence assessment. These methods provide a powerful tool for examining perturbations in the assumption of a model, particularly the effects of local perturbations of parameters of observations.


The local-influence approach to influence assessment is quitedifferent from the case deletion approach, comparisons are of
interest.






\subsection{Overall Influence}
An overall influence statistic measures the change in the objective function being minimized. For example, in
OLS regression, the residual sums of squares serves that purpose. In linear mixed models fit by
\index{maximum likelihood} maximum likelihood (ML) or \index{restricted maximum likelihood} restricted maximum likelihood (REML), an overall influence measure is the \index{likelihood distance} likelihood distance [Cook and Weisberg ].

%---------------------------------------------------------------------------%
\newpage
\section*{Extension of techniques to LME Models} %1.2

Model diagnostic techniques, well established for classical models, have since been adapted for use with linear mixed effects models.Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.

Beckman, Nachtsheim and Cook (1987) \citet{Beckman} applied the \index{local influence}local influence method of Cook (1986) to the analysis of the linear mixed model.

While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.

If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect the following

\begin{itemize}
\item the estimates of fixed effects,
\item the estimates of the precision of the fixed effects,
\item the estimates of the covariance parameters,
\item the estimates of the precision of the covariance parameters,
\item fitted and predicted values.
\end{itemize}

\newpage


Influence Diagnostics
Basic Idea and Statistics

The general idea of quantifying the influence of one or more observations relies on computing parameter estimates based on all data points, removing the cases in question from the data, refitting the model, and computing statistics based on the change between full-data and reduced-data estimation. 

Influence statistics can be coarsely grouped by the aspect of estimation that is their primary target:
overall measures compare changes in objective functions: (restricted) likelihood distance (Cook and Weisberg 1982, Ch. 5.2)
influence on parameter estimates: Cook’s  (Cook 1977, 1979), MDFFITS (Belsley, Kuh, and Welsch 1980, p. 32)
influence on precision of estimates: CovRatio and CovTrace
influence on fitted and predicted values: PRESS residual, PRESS statistic (Allen 1974), DFFITS (Belsley, Kuh, and Welsch 1980, p. 15)
outlier properties: internally and externally studentized residuals, leverage
For linear models for uncorrelated data, it is not necessary to refit the model after removing a data point in order to measure the impact of an observation on the model. The change in fixed effect estimates, residuals, residual sums of squares, and the variance-covariance matrix of the fixed effects can be computed based on the fit to the full data alone. By contrast, in mixed models several important complications arise. Data points can affect not only the fixed effects but also the covariance parameter estimates on which the fixed-effects estimates depend. 

Furthermore, closed-form expressions for computing the change in important model quantities might not be available.
This section provides background material for the various influence diagnostics available with the MIXED procedure. See the section Mixed Models Theory for relevant expressions and definitions. The parameter vector  denotes all unknown parameters in the  and  matrix.
The observations whose influence is being ascertained are represented by the set  and referred to simply as "the observations in ." The estimate of a parameter vector, such as , obtained from all observations except those in the set  is denoted . In case of a matrix , the notation  represents the matrix with the rows in  removed; these rows are collected in . If  is symmetric, then notation  implies removal of rows and columns. The vector  comprises the responses of the data points being removed, and  is the variance-covariance matrix of the remaining observations. When , lowercase notation emphasizes that single points are removed, such as .

\newpage

%------------------------------------------------------------%
\section*{Residuals}

Residuals are used to examine model assumptions and to detect outliers and potentially influential data
point. The raw residuals $r_{mi}$ and $r_{ci}$ are usually not well suited for these purposes.

\begin{itemize}
	\item Conditional Residuals $r_{ci}$
	\item Marginal Residuals $r_{mi}$
	\item 
\end{itemize}
%------------------------------------------------------------%
\subsection*{Conditional Residuals}

\subsection*{Marginal Residuals}

%------------------------------------------------------------%
\newpage
Distinction From Linear Models
\begin{itemize}
	\item The differences between perturbation and residual analysis in the linear model and the linear mixed model
	are connected to the important facts that b and b
	depend on the estimates of the covariance parameters,
	that b has the form of an (estimated) generalized least squares (GLS) estimator, and that 
	is a random
	vector.
	\item In a mixed model, you can consider the data in a conditional and an unconditional sense. If you imagine
	a particular realization of the random effects, then you are considering the conditional distribution
	Y|
	\item If you are interested in quantities averaged over all possible values of the random effects, then
	you are interested in Y; this is called the marginal formulation. In a clinical trial, for example, you
	may be interested in drug efficacy for a particular patient. If random effects vary by patient, that is a
	conditional problem. If you are interested in the drug efficacy in the population of all patients, you are
	using a marginal formulation. Correspondingly, there will be conditional and marginal residuals, for
	example.
	\item The estimates of the fixed effects  depend on the estimates of the covariance parameters. If you are
	interested in determining the influence of an observation on the analysis, you must determine whether
	this is influence on the fixed effects for a given value of the covariance parameters, influence on the
	covariance parameters, or influence on both.
	\item Mixed models are often used to analyze repeated measures and longitudinal data. The natural experimental
	or sampling unit in those studies is the entity that is repeatedly observed, rather than each
	individual repeated observation. For example, you may be analyzing monthly purchase records by
	customer. 
	\item An influential “data point” is then not necessarily a single purchase. You are probably more
	interested in determining the influential customer. This requires that you can measure the influence
	of sets of observations on the analysis, not just influence of individual observations.
	\item The computation of case deletion diagnostics in the classical model is made simple by the fact that
	%estimates of  and 2, which exclude the ith observation, can be %computed without re-fitting the
	model. Such update formulas are available in the mixed model only if you assume that the covariance
	parameters are not affected by the removal of the observation in question. This is rarely a reasonable
	assumption.
	\item The application of well-known concepts in model-data diagnostics to the mixed model can produce results
	that are at first counter-intuitive, since our understanding is steeped in the ordinary least squares
	(OLS) framework. As a consequence, we need to revisit these important concepts, ask whether they
	are “portable” to the mixed model, and gain new appreciation for their changed properties. An important
	example is the ostensibly simple concept of leverage. 
	\item The definition of leverage adopted by
	the MIXED procedure can, in some instances, produce negative values, which are mathematically
	impossible in OLS. Other measures that have been proposed may be non-negative, but trade other
	advantages. Another example are properties of residuals. While OLS residuals necessarily sum to
	zero in any model (with intercept), this not true of the residuals in many mixed models.
\end{itemize}
\newpage
%------------------------------------------------------------%
\subsection*{SUMMARY AND CONCLUSIONS}
Standard residual and influence diagnostics for linear models can be extended to linear mixed models. The
dependence of fixed-effects solutions on the covariance parameter estimates has important ramifications
in perturbation analysis. To gauge the full impact of a set of observations on the analysis, covariance
parameters need to be updated, which requires refitting of the model. 

The experimental INFLUENCE
option of the MODEL statement in the MIXED procedure (SAS 9.1) enables you to perform iterative and
noniterative influence analysis for individual observations and sets of observations.
%------------------------------------------------------------%
The conditional (subject-specific) and marginal (population-averaged) formulations in the linear mixed model
enable you to consider conditional residuals that use the estimated BLUPs of the random effects, and
marginal residuals which are deviations from the overall mean. Residuals using the BLUPs are useful to
diagnose whether the random effects components in the model are specified correctly, marginal residuals
are useful to diagnose the fixed-effects components. Both types of residuals are available in SAS 9.1 as an
experimental option of the MODEL statement in the MIXED procedure.
%------------------------------------------------------------%
It is important to note that influence analyses are performed under the assumption that the chosen model
is correct. Changing the model structure can alter the conclusions. Many other variance models have been
fit to the data presented in the repeated measures example. You need to see the conclusions about which
model component is affected in light of the model being fit. For example, modeling these data with a random
intercept and random slope for each child or an unstructured covariance matrix will affect your conclusions
about which children are influential on the analysis and how this influence manifests itself.
%------------------------------------------------------------%
\section{Summary of Paper}
%Summary of Schabenberger
Standard residual and influence diagnostics for linear models can be extended to LME models.
The dependence of the fixed effects solutions on the covariance parameters has important ramifications on the perturbation analysis.	
Calculating the studentized residuals-And influence statistics whereas each software procedure can calculate both conditional and marginal raw residuals, only SAs Proc Mixed is currently the only program that provide studentized residuals Which ave preferred for model diagnostics. The conditional Raw residuals ave not well suited to detecting outliers as are the studentized conditional residuals. (schabenbege r)


LME are flexible tools for the analysis of clustered and repeated measurement data. LME extend the capabilities of standard linear models by allowing unbalanced and missing data, as long as the missing data are MAR. Structured covariance matrices for both the random effects G and the residuals R. missing at Random.

A conditional residual is the difference between the observed valve and the predicted valve of a dependent variable- Influence diagnostics are formal techniques that allow the identification observation that heavily influence estimates of parameters.
To alleviate the problems with the interpretation of conditional residuals that may have unequal variances, we consider sealing.
Residuals obtained in this manner ave called studentized residuals.



\subsection{ITERATIVE VS. NONITERATIVE INFLUENCE ANALYSIS}
While the basic idea of influence analysis is straightforward, the implementation in mixed models can be
tricky. For example, update formulas for the fixed effects are available only when the covariance parameters
are assumed to be known. At most the profiled residual variance can be updated without refitting the model.
A measure of total influence requires updates of all model parameters, and the only way that this can be
achieved in general is by removing the observations in question and refitting the model. Because this “bruteforce”
method involves iterative reestimation of the covariance parameters, it is termed iterative influence
analysis. Reliance on closed-form update formulas for the fixed effects without updating the (un-profiled)
covariance parameters is termed a noniterative influence analysis.
An iterative analysis seems like a costly, computationally intensive enterprise. If you compute iterative
influence diagnostics for all n observations, then a total of n + 1 mixed models are fit iteratively. This does
not imply, of course, that the procedure’s execution time increases n-fold. Keep in mind that
\begin{itemize}
	\item iterative reestimation always starts at the converged full-data estimates. If a data point is not influential,
	then its removal will have little effect on the objective function and parameter estimates. Within
	one or two iterations, the process should arrive at the reduced-data estimates.
	\item if complete reestimation does require many iterations, then this is important information in itself. The
	likelihood surface has probably changed drastically, and the reduced-data estimates are moving away
\end{itemize}
from the full-data estimates.

\newpage

\subsection{Influential Observations : DFBeta and DFBetas}
% http://stats.stackexchange.com/questions/22161/how-to-read-cooks-distance-plots
Cook's distance refers to how far, on average, predicted y-values will move if the observation in question is dropped from the data set. dfbeta refers to how much a parameter estimate changes if the observation in question is dropped from the data set. Note that with k covariates, there will be k+1 dfbetas (the intercept,$\beta_0$, and 1 $\beta$ for each covariate). Cook's distance is presumably more important to you if you are doing predictive modeling, whereas dfbeta is more important in explanatory modeling.

\subsection{Cook's Distance}
% Interpretation
% http://stats.stackexchange.com/questions/22161/how-to-read-cooks-distance-plots %
Some texts tell you that points for which Cook's distance is higher than 1 are to be considered as influential. Other texts give you a threshold of $4/N$ or $4/(N−k−1)$, where N is the number of observations and k the number of explanatory variables. In your case the latter formula should yield a threshold around 0.1 .

John Fox (1), in his booklet on regression diagnostics is rather cautious when it comes to giving numerical thresholds. He advises the use of graphics and to examine in closer details the points with "values of D that are substantially larger than the rest". According to Fox, thresholds should just be used to enhance graphical displays.

In your case the observations 7 and 16 could be considered as influential. Well, I would at least have a closer look at them. The observation 29 is not substantially different from a couple of other observations.

(1) Fox, John. (1991). Regression Diagnostics: An Introduction. Sage Publications.

\newpage
\subsection{Leverage}
leverage is a term used in connection with regression analysis and, in particular, in analyses aimed at identifying those observations that are far away from corresponding average predictor values. Leverage points do not necessarily have a large effect on the outcome of fitting regression models.

Leverage points are those observations, if any, made at extreme or outlying values of the independent variables such that the lack of neighboring observations means that the fitted regression model will pass close to that particular observation.[1]

Modern computer packages for statistical analysis include, as part of their facilities for regression analysis, various quantitative measures for identifying influential observations: among these measures is partial leverage, a measure of how a variable contributes to the leverage of a datum.




%-------------------------------------------------------------- %

\subsection{Residual}
Residual (or error) represents unexplained (or residual) variation after fitting a regression model. It is the difference (or left over) between the observed value of the variable and the value suggested by the regression model.


%------------------------- %

The difference between the observed value of the dependent variable (y) and the predicted value (ŷ) is called the residual (e). Each data point has one residual.

Residual = Observed value - Predicted value 
\[e = y - \hat{y} \]

Both the sum and the mean of the residuals are equal to zero. That is, Σ e = 0 and e = 0.

%--------------------------------- %




\subsection{Introduction}
In statistics and optimization, statistical errors and residuals are two closely related and easily confused measures of the deviation of an observed value of an element of a statistical sample from its "theoretical value". The error (or disturbance) of an observed value is the deviation of the observed value from the (unobservable) true function value, while the residual of an observed value is the difference between the observed value and the estimated function value.

The distinction is most important in regression analysis, where it leads to the concept of studentized residuals.

%----------------------------- %
\subsection{Residual}
A residual (or fitting error), on the other hand, is an observable estimate of the unobservable statistical error. Consider the previous example with men's heights and suppose we have a random sample of n people. The sample mean could serve as a good estimator of the population mean. Then we have:

The difference between the height of each man in the sample and the unobservable population mean is a statistical error, whereas
The difference between the height of each man in the sample and the observable sample mean is a residual.
Note that the sum of the residuals within a random sample is necessarily zero, and thus the residuals are necessarily not independent. The statistical errors on the other hand are independent, and their sum within the random sample is almost surely not zero.

%------------------------------- %

Other uses of the word "error" in statistics: 

The use of the term "error" as discussed in the sections above is in the sense of a deviation of a value from a hypothetical unobserved value. At least two other uses also occur in statistics, both referring to observable prediction errors:

\begin{itemize}
	\item Mean square error or mean squared error (abbreviated MSE) and root mean square error (RMSE) refer to the amount by which the values predicted by an estimator differ from the quantities being estimated (typically outside the sample from which the model was estimated).
	
	\item 
	Sum of squared errors, typically abbreviated SSE or SSe, refers to the residual sum of squares (the sum of squared residuals) of a regression; this is the sum of the squares of the deviations of the actual values from the predicted values, within the sample used for estimation. Likewise, the sum of absolute errors (SAE) refers to the sum of the absolute values of the residuals, which is minimized in the least absolute deviations approach to regression.
	
\end{itemize}

%------------------------------- %
\newpage
\subsection{Studentization}
In statistics, a studentized residual is the quotient resulting from the division of a residual by an estimate of its standard deviation. Typically the standard deviations of residuals in a sample vary greatly from one data point to another even when the errors all have the same standard deviation, particularly in regression analysis; thus it does not make sense to compare residuals at different data points without first studentizing. It is a form of a Student's t-statistic, with the estimate of error varying between points.

This is an important technique in the detection of outliers. It is named in honor of William Sealey Gosset, who wrote under the pseudonym Student, and dividing by an estimate of scale is called studentizing, in analogy with standardizing and normalizing: see Studentization.


\subsection{Residual Plots}
A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis. If the points in a residual plot are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate.

Below the table on the left shows inputs and outputs from a simple linear regression analysis, and the chart on the right displays the residual (e) and independent variable (X) as a residual plot.

\begin{verbatim}
x	60	70	80	85	95
y	70	65	70	95	85
y.hat	65.411	71.849	78.288	81.507	87.945
e	4.589	-6.849	-8.288	13.493	-2.945
\end{verbatim}


The residual plot shows a fairly random pattern - the first residual is positive, the next two are negative, the fourth is positive, and the last residual is negative. This random pattern indicates that a linear model provides a decent fit to the data.

Below, the residual plots show three typical patterns. The first plot shows a random pattern, indicating a good fit for a linear model. The other plot patterns are non-random (U-shaped and inverted U), suggesting a better fit for a non-linear model.



%--------------------- %

\newpage
\subsection{Key Definitions}
\begin{description}
	\item[ Residual] The difference between the predicted value (based on the regression equation) and the actual, observed value.
	
	\item[ Outlier] In linear regression, an outlier is an observation with large residual. In other words, it is an observation whose dependent-variable value is unusual given its value on the predictor variables. An outlier may indicate a sample peculiarity or may indicate a data entry error or other problem.
	
	\item[ Leverage] An observation with an extreme value on a predictor variable is a point with high leverage. Leverage is a measure of how far an independent variable deviates from its mean. High leverage points can have a great amount of effect on the estimate of regression coefficients.
	
	\item[ Influence] An observation is said to be influential if removing the observation substantially changes the estimate of the regression coefficients.  Influence can be thought of as the product of leverage and outlierness.
	
	\item[ Cook's distance ] A measure that combines the information of leverage and residual of the observation.
\end{description}

%--------------------- %
\newpage
\subsection{Leverage}
In statistics, leverage is a term used in connection with regression analysis and, in particular, in analyses aimed at identifying those observations that are far away from corresponding average predictor values. Leverage points do not necessarily have a large effect on the outcome of fitting regression models.

Leverage points are those observations, if any, made at extreme or outlying values of the independent variables such that the lack of neighboring observations means that the fitted regression model will pass close to that particular observation.[1]

Modern computer packages for statistical analysis include, as part of their facilities for regression analysis, various quantitative measures for identifying influential observations: among these measures is partial leverage, a measure of how a variable contributes to the leverage of a datum.

\subsection{Cook's Distance}
In statistics, Cook's Distance or Cook's D is a commonly used estimate of the influence of a data point when performing least squares regression analysis.[1] In a practical ordinary least squares analysis, Cook's distance can be used in several ways: to indicate data points that are particularly worth checking for validity; to indicate regions of the design space where it would be good to be able to obtain more data points. It is named after the American statistician R. Dennis Cook, who introduced the concept in 1977.


\subsubsection{Interpretation}
Specifically $D_i$ can be interpreted as the distance one's estimates move within the confidence ellipsoid that represents a region of plausible values for the parameters.[clarification needed] This is shown by an alternative but equivalent representation of Cook's distance in terms of changes to the estimates of the regression parameters between the cases where the particular observation is either included or excluded from the regression analysis.



\end{document}


%------------------------------------------------------------%
\end{document}