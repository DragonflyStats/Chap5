\documentclass[]{article}

%opening
\title{Mixed Model Influence Diagnostics}
\author{Oliver Schabenberger, SAS}

\begin{document}

\maketitle


\begin{abstract}
Notes and Key Definitions from Schabenberger's paper
\end{abstract}
%------------------------------------------------------------%
\section*{Residuals}

Residuals are used to examine model assumptions and to detect outliers and potentially influential data
point. The raw residuals $r_{mi}$ and $r_{ci}$ are usually not well suited for these purposes.

\begin{itemize}
\item Conditional Residuals $r_{ci}$
\item Marginal Residuals $r_{mi}$
\item 
\end{itemize}
%------------------------------------------------------------%
\subsection*{Conditional Residuals}

\subsection*{Marginal Residuals}

%------------------------------------------------------------%
\newpage
Distinction From Linear Models
\begin{itemize}
\item The differences between perturbation and residual analysis in the linear model and the linear mixed model
are connected to the important facts that b and b
 depend on the estimates of the covariance parameters,
that b has the form of an (estimated) generalized least squares (GLS) estimator, and that 
 is a random
vector.
\item In a mixed model, you can consider the data in a conditional and an unconditional sense. If you imagine
a particular realization of the random effects, then you are considering the conditional distribution
Y|
\item If you are interested in quantities averaged over all possible values of the random effects, then
you are interested in Y; this is called the marginal formulation. In a clinical trial, for example, you
may be interested in drug efficacy for a particular patient. If random effects vary by patient, that is a
conditional problem. If you are interested in the drug efficacy in the population of all patients, you are
using a marginal formulation. Correspondingly, there will be conditional and marginal residuals, for
example.
\item The estimates of the fixed effects  depend on the estimates of the covariance parameters. If you are
interested in determining the influence of an observation on the analysis, you must determine whether
this is influence on the fixed effects for a given value of the covariance parameters, influence on the
covariance parameters, or influence on both.
\item Mixed models are often used to analyze repeated measures and longitudinal data. The natural experimental
or sampling unit in those studies is the entity that is repeatedly observed, rather than each
individual repeated observation. For example, you may be analyzing monthly purchase records by
customer. 
\item An influential ‚Äúdata point‚Äù is then not necessarily a single purchase. You are probably more
interested in determining the influential customer. This requires that you can measure the influence
of sets of observations on the analysis, not just influence of individual observations.
\item The computation of case deletion diagnostics in the classical model is made simple by the fact that
estimates of  and 2, which exclude the ith observation, can be computed without re-fitting the
model. Such update formulas are available in the mixed model only if you assume that the covariance
parameters are not affected by the removal of the observation in question. This is rarely a reasonable
assumption.
\item The application of well-known concepts in model-data diagnostics to the mixed model can produce results
that are at first counter-intuitive, since our understanding is steeped in the ordinary least squares
(OLS) framework. As a consequence, we need to revisit these important concepts, ask whether they
are ‚Äúportable‚Äù to the mixed model, and gain new appreciation for their changed properties. An important
example is the ostensibly simple concept of leverage. 
\item The definition of leverage adopted by
the MIXED procedure can, in some instances, produce negative values, which are mathematically
impossible in OLS. Other measures that have been proposed may be non-negative, but trade other
advantages. Another example are properties of residuals. While OLS residuals necessarily sum to
zero in any model (with intercept), this not true of the residuals in many mixed models.
\end{itemize}
\newpage
%------------------------------------------------------------%
\subsection*{SUMMARY AND CONCLUSIONS}
Standard residual and influence diagnostics for linear models can be extended to linear mixed models. The
dependence of fixed-effects solutions on the covariance parameter estimates has important ramifications
in perturbation analysis. To gauge the full impact of a set of observations on the analysis, covariance
parameters need to be updated, which requires refitting of the model. 

The experimental INFLUENCE
option of the MODEL statement in the MIXED procedure (SAS 9.1) enables you to perform iterative and
noniterative influence analysis for individual observations and sets of observations.
%------------------------------------------------------------%
The conditional (subject-specific) and marginal (population-averaged) formulations in the linear mixed model
enable you to consider conditional residuals that use the estimated BLUPs of the random effects, and
marginal residuals which are deviations from the overall mean. Residuals using the BLUPs are useful to
diagnose whether the random effects components in the model are specified correctly, marginal residuals
are useful to diagnose the fixed-effects components. Both types of residuals are available in SAS 9.1 as an
experimental option of the MODEL statement in the MIXED procedure.
%------------------------------------------------------------%
It is important to note that influence analyses are performed under the assumption that the chosen model
is correct. Changing the model structure can alter the conclusions. Many other variance models have been
fit to the data presented in the repeated measures example. You need to see the conclusions about which
model component is affected in light of the model being fit. For example, modeling these data with a random
intercept and random slope for each child or an unstructured covariance matrix will affect your conclusions
about which children are influential on the analysis and how this influence manifests itself.
%------------------------------------------------------------%
\asection{Summary of Paper}
%Summary of Schabenberger
Standard residual and influence diagnostics for linear models can be extended to LME models.
The dependence of the fixed effects solutions on the covariance parameters has important ramifications on the perturbation analysis.	
Calculating the student_zed residuals-And influence statistics whereas each software procedure can calculate both conditional and marginal raw residuals, only SAs Proc Mixed is currently the only program that provide student_zed residuals Which ave preferred for model diagnostics. The conditional Raw residuals ave not well suited to detecting outliers as are the studentized conditional residuals. (schabenbege r)
 
 
LME are flexible tools for the analysis of clustered and repeated measurement data. LME extend the capabilities of standard linear models by allowing unbalanced and missing data, as long as the missing data are MAR. Structured covariance matrices for both the random effects G and the residuals R. missing at Random.
 
A conditional residual is the difference between the observed valve and the predicted valve of a dependent variable- Influence diagnostics are formal techniques that allow the identification observation that heavily influence estimates of parameters.
To alleviate the problems with the interpretation of conditional residuals that may have unequal variances, we consider sealing.
Residuals obtained in this manner ave called studentized residuals.



\subsection{ITERATIVE VS. NONITERATIVE INFLUENCE ANALYSIS}
While the basic idea of influence analysis is straightforward, the implementation in mixed models can be
tricky. For example, update formulas for the fixed effects are available only when the covariance parameters
are assumed to be known. At most the profiled residual variance can be updated without refitting the model.
A measure of total influence requires updates of all model parameters, and the only way that this can be
achieved in general is by removing the observations in question and refitting the model. Because this ‚Äúbruteforce‚Äù
method involves iterative reestimation of the covariance parameters, it is termed iterative influence
analysis. Reliance on closed-form update formulas for the fixed effects without updating the (un-profiled)
covariance parameters is termed a noniterative influence analysis.
An iterative analysis seems like a costly, computationally intensive enterprise. If you compute iterative
influence diagnostics for all n observations, then a total of n + 1 mixed models are fit iteratively. This does
not imply, of course, that the procedure‚Äôs execution time increases n-fold. Keep in mind that
\begin{itemize}
\item iterative reestimation always starts at the converged full-data estimates. If a data point is not influential,
then its removal will have little effect on the objective function and parameter estimates. Within
one or two iterations, the process should arrive at the reduced-data estimates.
\item if complete reestimation does require many iterations, then this is important information in itself. The
likelihood surface has probably changed drastically, and the reduced-data estimates are moving away
\end{itemize}
from the full-data estimates.

%------------------------------------------------------------%
\end{document}
